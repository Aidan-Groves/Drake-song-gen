{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Qzjq8d6OUwtK",
        "outputId": "1ef77f7d-d8ef-4b64-c42b-e6c972a22795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f313c9b13a9c>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrogram_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drake_songs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drake_songs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m44100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drake_songs'"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "import requests\n",
        "import librosa\n",
        "\n",
        "\n",
        "os.makedirs('/content/drive/My Drive/drakemp3', exist_ok=True)\n",
        "\n",
        "audio_paths = [\n",
        "    '/content/drive/My Drive/drakemp3/Currents.mp3',\n",
        "    '/content/drive/My Drive/drakemp3/TextsGoGreen.mp3',\n",
        "    '/content/drive/My Drive/drakemp3/FallingBack.mp3'\n",
        "]\n",
        "\n",
        "\n",
        "spectrogram_folder = '/content/drake_spectrograms'\n",
        "os.makedirs(spectrogram_folder, exist_ok=True)\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    spectrogram = np.abs(librosa.stft(y))\n",
        "    np.save(os.path.join(spectrogram_folder, f'{os.path.splitext(os.path.basename(audio_path))[0]}.npy'), spectrogram)\n",
        "\n",
        "\n",
        "spectrogram_folder = '/content/drake_spectrograms'\n",
        "os.makedirs(spectrogram_folder, exist_ok=True)\n",
        "\n",
        "for audio_file in os.listdir('/content/drake_songs'):\n",
        "    audio_path = os.path.join('/content/drake_songs', audio_file)\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    spectrogram = np.abs(librosa.stft(y))\n",
        "    np.save(os.path.join(spectrogram_folder, f'{os.path.splitext(audio_file)[0]}.npy'), spectrogram)\n",
        "\n",
        "\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if len(gpus) > 0:\n",
        "    print(\"GPU is available.\")\n",
        "\n",
        "else:\n",
        "    print(\"No GPU detected. Running on CPU.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8SiBdqVhcBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load segmented spectrograms\n",
        "spectrogram_folder = '/content/drake_spectrograms'\n",
        "segmented_folder = '/content/drake_segmented'\n",
        "\n",
        "os.makedirs(segmented_folder, exist_ok=True)\n",
        "\n",
        "# Define segment length and hop length\n",
        "segment_length = 100  # Define the length of each segment\n",
        "hop_length = 50  # Define hop length for segmentation\n",
        "\n",
        "for spectrogram_file in os.listdir(spectrogram_folder):\n",
        "    spectrogram_path = os.path.join(spectrogram_folder, spectrogram_file)\n",
        "    spectrogram = np.load(spectrogram_path)\n",
        "\n",
        "    # Segment the spectrogram\n",
        "    num_segments = (spectrogram.shape[1] - segment_length) // hop_length\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = spectrogram[:, i * hop_length : i * hop_length + segment_length]\n",
        "        np.save(os.path.join(segmented_folder, f'{os.path.splitext(spectrogram_file)[0]}_{i}.npy'), segment)\n"
      ],
      "metadata": {
        "id": "v07UEx-5dRPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train RNN (LSTM for example)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Load segmented spectrograms\n",
        "segmented_folder = '/content/drake_segmented'\n",
        "\n",
        "# Collect segmented spectrograms\n",
        "segments = []\n",
        "for segmented_file in os.listdir(segmented_folder):\n",
        "    segmented_path = os.path.join(segmented_folder, segmented_file)\n",
        "    segment = np.load(segmented_path)\n",
        "    segments.append(segment)\n",
        "\n",
        "# Convert segments to numpy array\n",
        "segments = np.array(segments)\n",
        "\n",
        "# Calculate num_features based on the shape of segments\n",
        "num_features = segments.shape[1] * segments.shape[2]\n",
        "\n",
        "# Define RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=128, input_shape=segments.shape[1:], return_sequences=True))\n",
        "model.add(Dense(units=segments.shape[2]))  # Output layer matching segment_length\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(segments, segments, epochs=10, batch_size=32)  # Adjust epochs and batch_size as needed\n",
        "\n"
      ],
      "metadata": {
        "id": "iHx2bIWtgohq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3RvAh8WrHQz",
        "outputId": "f6922433-83e3-4857-ea50-f0df09b6b349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to read text from a CSV file\n",
        "def read_text_from_csv(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    lyrics = data['lyrics'].str.lower().str.cat(sep=' ')\n",
        "    return lyrics\n",
        "\n",
        "# Path to the CSV file containing additional Drake lyrics\n",
        "lyrics_csv_path = '/content/drive/My Drive/drakemp3/drake_data.csv'\n",
        "drake_lyrics_additional = read_text_from_csv(lyrics_csv_path)\n",
        "\n",
        "# Path to the existing text file of Drake's lyrics\n",
        "lyrics_file_path = '/content/drive/My Drive/drakemp3/drake-lyrics.txt'\n",
        "drake_lyrics = read_text_from_file(lyrics_file_path)\n",
        "\n",
        "# Combining the additional lyrics with the existing ones\n",
        "drake_lyrics += drake_lyrics_additional\n",
        "\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Function to read text from a single .txt file\n",
        "def read_text_from_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read().lower()\n",
        "    return text\n",
        "\n",
        "lyrics_file_path = '/content/drive/My Drive/drakemp3/drake-lyrics.txt'\n",
        "drake_lyrics = read_text_from_file(lyrics_file_path)\n",
        "\n",
        "# Create a character-level mapping\n",
        "chars = sorted(list(set(drake_lyrics)))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "idx_to_char = {idx: ch for idx, ch in enumerate(chars)}\n",
        "\n",
        "max_len = 250  # Increased sequence length\n",
        "step = 5  # Increased step size for overlapping sequences\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(drake_lyrics) - max_len, step):\n",
        "    sequences.append(drake_lyrics[i:i + max_len])\n",
        "    next_chars.append(drake_lyrics[i + max_len])\n",
        "\n",
        "# Vectorize sequences\n",
        "x = np.zeros((len(sequences), max_len, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i, t, char_to_idx[char]] = 1\n",
        "    y[i, char_to_idx[next_chars[i]]] = 1\n",
        "\n",
        "# TensorFlow configuration to utilize GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# Build an RNN model with increased complexity\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(max_len, len(chars)), return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model for more epochs\n",
        "model.fit(x, y, batch_size=256, epochs=75)  # Increased epochs\n",
        "\n",
        "# Generate text using the trained model with adjusted temperature\n",
        "seed_text = \"I'm feeling\"  # Provide a seed text to start generating\n",
        "generated_text = seed_text.lower()\n",
        "\n",
        "temperature = 0.2  # Adjust temperature for diversity in text generation\n",
        "\n",
        "for _ in range(1000):  # Generate longer lyrics\n",
        "    sampled = np.zeros((1, max_len, len(chars)))\n",
        "    for t, char in enumerate(generated_text[-max_len:]):\n",
        "        sampled[0, t, char_to_idx[char]] = 1.\n",
        "\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = np.random.choice(len(chars), p=preds)\n",
        "    next_char = idx_to_char[next_index]\n",
        "\n",
        "    generated_text += next_char\n",
        "\n",
        "# Post-processing for removing unwanted characters and repeated sequences\n",
        "generated_text = re.sub(r'[^a-zA-Z\\s]', '', generated_text)\n",
        "words = generated_text.split()\n",
        "filtered_words = [words[i] for i in range(len(words)) if i == 0 or words[i] != words[i - 1]]\n",
        "generated_text = ' '.join(filtered_words)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbL9CygUjBTb",
        "outputId": "5e33b2ff-f0a8-4255-acb4-5c1716af0409"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Num GPUs Available: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-6bc3615e4549>:57: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sequences), max_len, len(chars)), dtype=np.bool)\n",
            "<ipython-input-11-6bc3615e4549>:58: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7f73f52c7640>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 101, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "237/237 [==============================] - 77s 93ms/step - loss: 3.0277\n",
            "Epoch 2/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 2.6361\n",
            "Epoch 3/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 2.3595\n",
            "Epoch 4/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 2.2564\n",
            "Epoch 5/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 2.1793\n",
            "Epoch 6/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 2.1155\n",
            "Epoch 7/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 2.0638\n",
            "Epoch 8/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 2.0200\n",
            "Epoch 9/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.9792\n",
            "Epoch 10/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.9463\n",
            "Epoch 11/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.9090\n",
            "Epoch 12/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.8765\n",
            "Epoch 13/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.8493\n",
            "Epoch 14/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.8212\n",
            "Epoch 15/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.7962\n",
            "Epoch 16/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.7727\n",
            "Epoch 17/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.7518\n",
            "Epoch 18/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.7284\n",
            "Epoch 19/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.7086\n",
            "Epoch 20/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.6895\n",
            "Epoch 21/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.6708\n",
            "Epoch 22/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.6522\n",
            "Epoch 23/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.6379\n",
            "Epoch 24/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.6199\n",
            "Epoch 25/75\n",
            "237/237 [==============================] - 22s 91ms/step - loss: 1.6020\n",
            "Epoch 26/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.5869\n",
            "Epoch 27/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.5723\n",
            "Epoch 28/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.5582\n",
            "Epoch 29/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.5421\n",
            "Epoch 30/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.5285\n",
            "Epoch 31/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.5125\n",
            "Epoch 32/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.4976\n",
            "Epoch 33/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.4842\n",
            "Epoch 34/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.4693\n",
            "Epoch 35/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.4545\n",
            "Epoch 36/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.4387\n",
            "Epoch 37/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.4256\n",
            "Epoch 38/75\n",
            "237/237 [==============================] - 21s 91ms/step - loss: 1.4101\n",
            "Epoch 39/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.3971\n",
            "Epoch 40/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.3817\n",
            "Epoch 41/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.3647\n",
            "Epoch 42/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.3502\n",
            "Epoch 43/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.3373\n",
            "Epoch 44/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.3209\n",
            "Epoch 45/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.3069\n",
            "Epoch 46/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.2892\n",
            "Epoch 47/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.2744\n",
            "Epoch 48/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.2584\n",
            "Epoch 49/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.2413\n",
            "Epoch 50/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.2267\n",
            "Epoch 51/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.2085\n",
            "Epoch 52/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.1926\n",
            "Epoch 53/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.1774\n",
            "Epoch 54/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.1635\n",
            "Epoch 55/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.1439\n",
            "Epoch 56/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 1.1271\n",
            "Epoch 57/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.1085\n",
            "Epoch 58/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.0921\n",
            "Epoch 59/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 1.0740\n",
            "Epoch 60/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 1.0589\n",
            "Epoch 61/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 1.0421\n",
            "Epoch 62/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 1.0223\n",
            "Epoch 63/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 1.0048\n",
            "Epoch 64/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.9865\n",
            "Epoch 65/75\n",
            "237/237 [==============================] - 21s 90ms/step - loss: 0.9691\n",
            "Epoch 66/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.9520\n",
            "Epoch 67/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.9320\n",
            "Epoch 68/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.9151\n",
            "Epoch 69/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.8968\n",
            "Epoch 70/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.8804\n",
            "Epoch 71/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.8592\n",
            "Epoch 72/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.8432\n",
            "Epoch 73/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.8274\n",
            "Epoch 74/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.8089\n",
            "Epoch 75/75\n",
            "237/237 [==============================] - 21s 89ms/step - loss: 0.7885\n",
            "Bleu Score: 7.294145378628693e-232\n",
            "im feelingaohio oauehio h ooaoahoahiahho ao hioaao aieiiaoa aaa haaoyaryii e o oeo rioia oaor aaoa aoah oneaoroooa ooo h ehonao oh oeoe hiraa wtae oaoo odo iyooo oatiaoia h lia ow oo p pnpddd lust lant back that they seeplene gone hassesside and me ohoh no got a loth oot as i sty too just racouse i know when that hotly get it at all mm out you looked and where i kid to the comite has see carcess for side she tnow whats real i can get im lone i spess bet with my mond now maia back in the mamms on when driak it aint a record and i top with neess detta and im take i neord me thit in tha gattest in the couple taycion town ie comparaha take i mean one thing h you know outhernever fine theres doink to hodain on the close whe n tuend cause you done tell me i hit rejust us ahand her go the road love with the agers and comprone out hare what they ask me to mant the trouth that drops of yourself you the not singe it pasing thats a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"I'm feeling good\"  # Provide a seed text to start generating\n",
        "generated_text = seed_text.lower()\n",
        "\n",
        "temperature = .1  # Adjust temperature for diversity in text generation\n",
        "\n",
        "for _ in range(1000):  # Generate longer lyrics\n",
        "    sampled = np.zeros((1, max_len, len(chars)))\n",
        "    for t, char in enumerate(generated_text[-max_len:]):\n",
        "        sampled[0, t, char_to_idx[char]] = 1.\n",
        "\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = np.random.choice(len(chars), p=preds)\n",
        "    next_char = idx_to_char[next_index]\n",
        "\n",
        "    generated_text += next_char\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShFzF061I4_p",
        "outputId": "691d3ad0-59d8-49cd-c5bb-9e3d42e2a504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i'm feeling goodt\n",
            "\n",
            "y.dhamobfdowam\n",
            "faaetpee-aif\n",
            "baota.\n",
            "ttbida\n",
            "endaaat\n",
            "\n",
            "as\n",
            "deebytp\n",
            ".tde\n",
            "wgdstta\n",
            " d\n",
            "\n",
            "aaptbbwoahawwaaab\n",
            ".tayw\n",
            "ad.eeedw\n",
            "atb\n",
            ".aaaauatshhna'nd micain\n",
            "yea.\n",
            "but i know we know i don't know we're a simper i meat with it me always so it's on, where it wat am... (ohah, oover toden toog.\n",
            "\n",
            "i swou?\n",
            "i just knomadin how you just been here, i'm gettin' plissen\n",
            "we always still\n",
            "i'm clot ying this shit, and what yea's won you about whenent their out of men\n",
            "if chish goode rigghas back fou up\n",
            "trying to the conight\n",
            "relatee dargit's somethin money would get really winnat so hopies (someded you would tige, i'm too good, getting be just can't be done like you chough but i want to trebotess to be lougnt than you ain't you\n",
            "lights better that's been extine it bigga\n",
            "just want we can cur some stripper\n",
            "i get it and cause wat't don't have for you\n",
            "this she was her lasters you told it\n",
            "girl, and i've bad going nigga\n",
            "do to be a nigga, i ain't no lever when i king throught up to boprotite\n",
            "why i call as a tiru\n",
            "i'v fe ifu'cin\n"
          ]
        }
      ]
    }
  ]
}